{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset simpel\n",
    "This will be the final iteration of our iteration (no phun intented).\n",
    "We will try to make the entire dataloading process faster and easier using the less = more principle.\n",
    "We will also randomize from which chunk of data we are receiving a batch of slides data and apply padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sys import path\n",
    "\n",
    "path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-13 20:27:33.439 | INFO     | src.data.make_dataset:get_eeg:27 - Data is downloaded to /tmp/.keras/datasets/eeg.\n",
      "2022-06-13 20:27:33.440 | INFO     | src.data.make_dataset:get_eeg_data:34 - /tmp/.keras/datasets/eeg already exists, skipping download\n"
     ]
    }
   ],
   "source": [
    "from src.data.make_dataset import get_eeg\n",
    "datapath = get_eeg(data_dir=\"../data/raw\")\n",
    "path = \"../data/raw\"\n",
    "from src.data.make_dataset import get_eeg_data\n",
    "data = get_eeg_data(datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new iterator chunks the data in the initialize function. The iterator then only does very minor work during it's iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.bufferedEEG import EEGBufferIterator\n",
    "from src.data.make_eeg_data import EEGListDataset\n",
    "\n",
    "dsNew = EEGListDataset(data=data[0].tolist())\n",
    "dataloader = EEGBufferIterator(dsNew, batchsize=3, horizon=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 14])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets mostly even sized chunks of 'batch size' \n",
    "# with the exeption of chunks which end with another Y value\n",
    "# padding not implemented as I do not understand why\n",
    "x = next(iter(dataloader))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the shape is exactly what we expected and we can then check whether the sliding window functions correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4393.8500, 4063.5900, 4302.0500, 4167.6900, 4352.3100, 4617.4400,\n",
       "        4069.2300, 4584.1000, 4163.0800, 4209.7400, 4211.7900, 4303.0800,\n",
       "        4642.0500, 4425.6400], dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with the sliding windows the second window of the first batch \n",
    "# should be the same as the first window of the second batch\n",
    "x[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4393.8500, 4063.5900, 4302.0500, 4167.6900, 4352.3100, 4617.4400,\n",
       "        4069.2300, 4584.1000, 4163.0800, 4209.7400, 4211.7900, 4303.0800,\n",
       "        4642.0500, 4425.6400], dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1][0]\n",
    "# and this checks out!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16b8f312320cd240106b9ea4d318428341e8727b3c7d5fc1f73cfe4a3d9868ce"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('deep-learning-E14Cnx23-py3.9': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
