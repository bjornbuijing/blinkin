{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "We will explore this dataset: https://archive.ics.uci.edu/ml/datasets/EEG+Eye+State#\n",
    "\n",
    "> All data is from one continuous EEG measurement with the Emotiv EEG Neuroheadset. The duration of the measurement was 117 seconds. The eye state was detected via a camera during the EEG measurement and added later manually to the file after analysing the video frames. '1' indicates the eye-closed and '0' the eye-open state. All values are in chronological order with the first measured value at the top of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sys import path\n",
    "import torch\n",
    "import torch.utils.data.dataloader\n",
    "import numpy as np\n",
    "path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "data_dir = \"../../data/raw\"\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00264/EEG%20Eye%20State.arff\"\n",
    "datapath = tf.keras.utils.get_file(\n",
    "        \"eeg\", origin=url, untar=False, cache_dir=data_dir\n",
    "    )\n",
    "\n",
    "from scipy.io import arff\n",
    "data = arff.loadarff(datapath)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, scipy.io.arff._arffread.MetaData)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data[0]) , type (data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata = data[0].tolist()\n",
    "type(newdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Tuple\n",
    "Tensor = torch.Tensor\n",
    "\n",
    "class BaseListDataset():\n",
    "    \"\"\"Base class for loading list data\n",
    "    \"\"\"\n",
    "    def __init__(self, data: list):\n",
    "        self.data = data\n",
    "        self.dataset = []\n",
    "        self.process_data()\n",
    "    \n",
    "    def process_data(self) -> None:\n",
    "        # abstract function which needs to be inherited\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[Tensor, int]:\n",
    "        return self.dataset[idx]\n",
    "\n",
    "class EEGListDataset(BaseListDataset):\n",
    "    \"\"\"Processes data for EEG Lists\n",
    "\n",
    "    Args:\n",
    "        BaseListDataset (_type_): base class for list data\n",
    "    \"\"\"\n",
    "    def process_data(self) -> None:\n",
    "        for record in self.data:\n",
    "            x = torch.tensor([record[0],record[1],record[2],record[3],\n",
    "                             record[4],record[5],record[6],record[7],\n",
    "                             record[8],record[9],record[10],record[11],\n",
    "                             record[12],record[13]],dtype=float\n",
    "                            )\n",
    "            y= torch.tensor(int(record[14]))\n",
    "            self.dataset.append((x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsNew = EEGListDataset(data=data[0].tolist())\n",
    "x,y = dsNew[12000]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class BaseDataIterator:\n",
    "    def __init__(self, dataset: BaseListDataset, batchsize: int):\n",
    "        self.dataset = dataset\n",
    "        self.batchsize = batchsize\n",
    "        self.curindex = 0\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        # the lenght is the amount of batches\n",
    "        return int(len(self.dataset) / self.batchsize)\n",
    "\n",
    "    def __iter__(self) -> BaseDataIterator:\n",
    "        # initialize index\n",
    "        self.index = 0\n",
    "        self.index_list = torch.randperm(len(self.dataset))\n",
    "        return self\n",
    "    \n",
    "    def batchloop(self) -> Tuple[Tensor, Tensor]:\n",
    "        X = []  # noqa N806\n",
    "        Y = []  # noqa N806\n",
    "        # fill the batch\n",
    "        for _ in range(self.batchsize):\n",
    "            x, y = self.dataset[int(self.index_list[self.index])]\n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "            self.index += 1\n",
    "        return X, Y\n",
    "\n",
    "    def __next__(self) -> Tuple[Tensor, Tensor]:\n",
    "        if self.index <= (len(self.dataset) - self.batchsize):\n",
    "            X, Y = self.batchloop()\n",
    "            return X, Y\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "\n",
    "class PaddedDatagenerator(BaseDataIterator):\n",
    "    # again, we inherit everything from the baseclass\n",
    "    def __init__(self, dataset: BaseListDataset\t, batchsize: int) -> None:\n",
    "        # we initialize the super class BaseDataIterator\n",
    "        # we now have everything the BaseDataIterator can do, for free\n",
    "        super().__init__(dataset, batchsize)\n",
    "    \n",
    "    def __next__(self) -> Tuple[Tensor, Tensor]:\n",
    "        if self.index <= (len(self.dataset) - self.batchsize):\n",
    "            X, Y = self.batchloop()\n",
    "            # I do not have a clue why this function returns a tensort and torch.tensor(X) gives me an error\n",
    "            X_ = pad_sequence(X, batch_first=True, padding_value=0)  # noqa N806\n",
    "            return X_, torch.tensor(Y)\n",
    "        else:\n",
    "            raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = PaddedDatagenerator(dsNew, batchsize=32)\n",
    "testloader = PaddedDatagenerator(dsNew, batchsize=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3342-14980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1,  ..., 1, 1, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(trainloader))\n",
    "x.shape, y.shape\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SwitchIterator:\n",
    "    def __init__(self, dataset: BaseListDataset):\n",
    "        self.dataset = dataset\n",
    "        self.curindex = 0\n",
    "        self.index = 0\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        # the lenght is the amount of batches\n",
    "        return int(len(self.dataset) / self.batchsize)\n",
    "\n",
    "    def __iter__(self) -> BaseDataIterator:\n",
    "        # initialize index\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def batchloop(self) -> Tuple[Tensor, Tensor]:\n",
    "        X = []  # noqa N806\n",
    "        Y = []  # noqa N806\n",
    "        # fill the batch\n",
    "        x, y = self.dataset[int(self.index)]\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "        self.index = self.index + 1 \n",
    "        currentY = y\n",
    "        while y == currentY:\n",
    "            if self.index +1 < len(self.dataset):\n",
    "                X.append(x)\n",
    "                Y.append(y)  \n",
    "                self.index = self.index + 1      \n",
    "                x, y = self.dataset[int(self.index)]                   \n",
    "            else:\n",
    "                self.index = 0\n",
    "                break                               \n",
    "     \n",
    "        return X, Y\n",
    "\n",
    "    def __next__(self) -> Tuple[Tensor, Tensor]:\n",
    "        if self.index < (len(self.dataset)):            \n",
    "            X, Y = self.batchloop()\n",
    "            return X, Y\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "\n",
    "class SwitchPaddedDatagenerator(SwitchIterator):\n",
    "    # again, we inherit everything from the baseclass\n",
    "    def __init__(self, dataset: BaseListDataset) -> None:\n",
    "        # we initialize the super class BaseDataIterator\n",
    "        # we now have everything the BaseDataIterator can do, for free\n",
    "        super().__init__(dataset)\n",
    "    \n",
    "    def __next__(self) -> Tuple[Tensor, Tensor]:\n",
    "        if self.index < (len(self.dataset)):\n",
    "            X, Y = self.batchloop()\n",
    "            # we just want to add padding\n",
    "            X_ = pad_sequence(X, batch_first=True, padding_value=0)  # noqa N806\n",
    "            return X_, torch.tensor(Y)\n",
    "        else:\n",
    "            raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = SwitchPaddedDatagenerator(dsNew)\n",
    "testloader = SwitchPaddedDatagenerator(dsNew)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4352-14980\n",
      "5244-14980\n",
      "5928-14980\n",
      "6653-14980\n",
      "9054-14980\n",
      "11105-14980\n",
      "12076-14980\n",
      "12728-14980\n",
      "12771-14980\n",
      "12976-14980\n",
      "13028-14980\n",
      "14217-14980\n",
      "14289-14980\n",
      "14959-14980\n",
      "0-14980\n",
      "188-14980\n",
      "871-14980\n",
      "1336-14980\n",
      "1638-14980\n",
      "2176-14980\n",
      "2633-14980\n",
      "2900-14980\n",
      "2927-14980\n",
      "3342-14980\n",
      "4352-14980\n",
      "5244-14980\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,27):\n",
    "    x, y = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11105-14980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([971, 14])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(trainloader))\n",
    "x.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1,  ..., 1, 1, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGBatchIterator:\n",
    "    def __init__(self, dataset: BaseListDataset, batchsize: int):\n",
    "        self.dataset = dataset\n",
    "        self.batchsize = batchsize\n",
    "        self.curindex = 0\n",
    "        self.index = 0\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        # the lenght is the amount of batches\n",
    "        return int(len(self.dataset) / self.batchsize)\n",
    "\n",
    "    def __iter__(self) -> BaseDataIterator:\n",
    "        # initialize index\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def batchloop(self) -> Tuple[Tensor, Tensor]:\n",
    "        X = []  # noqa N806\n",
    "        Y = []  # noqa N806\n",
    "        # fill the batch\n",
    "        x, y = self.dataset[int(self.index)]\n",
    "        count = 1\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "        self.index = self.index + 1 \n",
    "        currentY = y\n",
    "        while y == currentY and count < self.batchsize :\n",
    "            if self.index == self.__len__:\n",
    "                break\n",
    "            else:                                 \n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "                count = count +1\n",
    "                self.index = self.index + 1      \n",
    "                x, y = self.dataset[int(self.index)]        \n",
    "        return X, Y\n",
    "\n",
    "    def __next__(self) -> Tuple[Tensor, Tensor]:\n",
    "        if self.index <= (len(self.dataset)):\n",
    "            X, Y = self.batchloop()\n",
    "            # we just want to add padding\n",
    "            X_ = pad_sequence(X, batch_first=True, padding_value=0)  # noqa N806\n",
    "            return X_, torch.tensor(Y)\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader2 = EEGBatchIterator(dsNew, batchsize=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([17, 14]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(trainloader2))\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4296.4100, 4004.1000, 4263.5900, 4122.0500, 4342.0500, 4590.7700,\n",
       "         4082.0500, 4606.1500, 4176.9200, 4211.2800, 4194.3600, 4267.1800,\n",
       "         4602.0500, 4360.5100],\n",
       "        [4296.4100, 4004.1000, 4263.5900, 4122.0500, 4342.0500, 4590.7700,\n",
       "         4082.0500, 4606.1500, 4176.9200, 4211.2800, 4194.3600, 4267.1800,\n",
       "         4602.0500, 4360.5100],\n",
       "        [4313.3300, 4008.2100, 4268.7200, 4136.9200, 4342.5600, 4595.3800,\n",
       "         4091.2800, 4623.0800, 4207.6900, 4222.0500, 4206.1500, 4283.0800,\n",
       "         4607.6900, 4362.5600],\n",
       "        [4316.4100, 4014.3600, 4278.9700, 4139.4900, 4337.9500, 4583.5900,\n",
       "         4085.6400, 4614.8700, 4198.4600, 4234.8700, 4212.3100, 4285.6400,\n",
       "         4620.0000, 4378.4600],\n",
       "        [4320.0000, 4017.4400, 4284.1000, 4137.9500, 4337.4400, 4586.1500,\n",
       "         4086.6700, 4612.3100, 4198.9700, 4242.5600, 4217.9500, 4284.6200,\n",
       "         4626.6700, 4389.7400],\n",
       "        [4328.2100, 4021.0300, 4283.0800, 4141.0300, 4332.8200, 4599.4900,\n",
       "         4100.0000, 4630.2600, 4217.9500, 4248.2100, 4226.6700, 4291.7900,\n",
       "         4632.8200, 4388.7200],\n",
       "        [4325.1300, 4019.4900, 4281.5400, 4136.4100, 4327.6900, 4606.1500,\n",
       "         4109.7400, 4638.4600, 4218.9700, 4242.5600, 4228.2100, 4300.0000,\n",
       "         4636.4100, 4383.5900],\n",
       "        [4312.8200, 4010.2600, 4282.0500, 4129.7400, 4331.2800, 4606.6700,\n",
       "         4108.7200, 4628.7200, 4212.3100, 4233.8500, 4221.5400, 4300.0000,\n",
       "         4629.7400, 4380.0000],\n",
       "        [4309.7400, 4005.6400, 4278.4600, 4133.3300, 4335.3800, 4606.1500,\n",
       "         4105.1300, 4628.2100, 4216.9200, 4237.4400, 4214.8700, 4291.2800,\n",
       "         4620.5100, 4372.8200],\n",
       "        [4307.1800, 4005.1300, 4269.2300, 4130.2600, 4334.3600, 4607.1800,\n",
       "         4103.0800, 4629.2300, 4211.2800, 4233.8500, 4205.6400, 4278.4600,\n",
       "         4612.3100, 4360.0000],\n",
       "        [4300.0000, 4000.5100, 4260.0000, 4121.5400, 4333.8500, 4602.0500,\n",
       "         4095.3800, 4612.8200, 4189.2300, 4222.0500, 4196.9200, 4269.7400,\n",
       "         4606.1500, 4349.7400],\n",
       "        [4299.4900, 3996.9200, 4253.8500, 4125.6400, 4337.9500, 4590.2600,\n",
       "         4086.1500, 4598.4600, 4179.4900, 4225.6400, 4195.3800, 4266.1500,\n",
       "         4607.1800, 4352.8200],\n",
       "        [4292.8200, 4000.0000, 4249.7400, 4130.2600, 4340.5100, 4588.2100,\n",
       "         4082.5600, 4596.9200, 4183.0800, 4230.2600, 4195.9000, 4263.0800,\n",
       "         4609.2300, 4356.4100],\n",
       "        [4281.5400, 4001.5400, 4245.6400, 4120.0000, 4334.8700, 4595.9000,\n",
       "         4080.5100, 4592.8200, 4178.4600, 4214.8700, 4191.7900, 4257.9500,\n",
       "         4605.6400, 4347.6900],\n",
       "        [4288.2100, 4000.0000, 4244.6200, 4118.9700, 4334.3600, 4600.5100,\n",
       "         4081.0300, 4597.9500, 4183.0800, 4204.6200, 4188.2100, 4260.5100,\n",
       "         4603.0800, 4345.6400],\n",
       "        [4301.5400, 4005.6400, 4251.2800, 4134.8700, 4345.1300, 4606.1500,\n",
       "         4088.2100, 4617.9500, 4207.1800, 4216.9200, 4192.3100, 4269.7400,\n",
       "         4603.5900, 4353.8500],\n",
       "        [4299.4900, 4013.8500, 4260.0000, 4140.5100, 4349.7400, 4612.8200,\n",
       "         4091.7900, 4625.6400, 4214.8700, 4231.7900, 4196.9200, 4271.2800,\n",
       "         4603.5900, 4355.9000],\n",
       "        [4295.3800, 4015.3800, 4262.5600, 4137.4400, 4347.1800, 4614.8700,\n",
       "         4090.2600, 4620.0000, 4210.7700, 4233.8500, 4196.9200, 4268.2100,\n",
       "         4605.6400, 4358.9700],\n",
       "        [4307.1800, 4016.4100, 4267.6900, 4138.4600, 4348.7200, 4615.9000,\n",
       "         4093.8500, 4625.1300, 4220.0000, 4233.8500, 4200.5100, 4275.3800,\n",
       "         4614.3600, 4365.1300],\n",
       "        [4318.9700, 4021.5400, 4277.4400, 4141.5400, 4348.7200, 4612.3100,\n",
       "         4099.4900, 4632.8200, 4224.1000, 4244.1000, 4214.3600, 4288.7200,\n",
       "         4629.7400, 4371.2800],\n",
       "        [4317.4400, 4021.5400, 4281.5400, 4140.5100, 4347.6900, 4606.6700,\n",
       "         4095.3800, 4625.1300, 4206.6700, 4252.8200, 4222.5600, 4294.3600,\n",
       "         4640.0000, 4381.0300],\n",
       "        [4313.3300, 4011.2800, 4278.4600, 4136.4100, 4345.1300, 4608.7200,\n",
       "         4090.2600, 4611.7900, 4190.2600, 4241.5400, 4214.8700, 4289.7400,\n",
       "         4632.8200, 4380.0000],\n",
       "        [4314.8700, 4002.5600, 4271.7900, 4134.3600, 4335.3800, 4609.7400,\n",
       "         4093.8500, 4607.1800, 4189.7400, 4222.0500, 4205.1300, 4282.5600,\n",
       "         4622.0500, 4367.1800],\n",
       "        [4314.3600, 4009.2300, 4271.2800, 4137.4400, 4334.8700, 4604.6200,\n",
       "         4097.9500, 4613.8500, 4201.5400, 4224.6200, 4206.6700, 4283.5900,\n",
       "         4626.6700, 4370.2600],\n",
       "        [4312.3100, 4018.4600, 4277.4400, 4142.0500, 4346.1500, 4606.1500,\n",
       "         4096.9200, 4622.0500, 4213.8500, 4240.0000, 4217.4400, 4288.7200,\n",
       "         4636.4100, 4380.0000],\n",
       "        [4311.7900, 4013.3300, 4279.4900, 4138.9700, 4346.1500, 4608.2100,\n",
       "         4094.8700, 4623.5900, 4213.8500, 4243.5900, 4221.5400, 4290.7700,\n",
       "         4635.3800, 4373.3300],\n",
       "        [4306.1500, 4002.5600, 4277.4400, 4135.3800, 4339.4900, 4602.0500,\n",
       "         4094.3600, 4625.1300, 4208.7200, 4237.4400, 4216.4100, 4288.7200,\n",
       "         4628.2100, 4366.1500],\n",
       "        [4301.5400, 4001.0300, 4274.3600, 4135.3800, 4341.0300, 4600.0000,\n",
       "         4088.7200, 4628.7200, 4210.7700, 4236.4100, 4209.7400, 4284.1000,\n",
       "         4623.0800, 4369.2300],\n",
       "        [4308.7200, 4009.7400, 4268.7200, 4136.9200, 4343.5900, 4608.2100,\n",
       "         4083.0800, 4625.6400, 4213.3300, 4241.5400, 4210.2600, 4282.0500,\n",
       "         4624.6200, 4366.6700],\n",
       "        [4315.3800, 4021.5400, 4267.1800, 4140.5100, 4347.1800, 4613.3300,\n",
       "         4089.2300, 4621.0300, 4209.7400, 4238.4600, 4213.8500, 4282.0500,\n",
       "         4625.1300, 4359.4900],\n",
       "        [4306.6700, 4016.9200, 4268.7200, 4142.0500, 4350.7700, 4609.2300,\n",
       "         4097.4400, 4620.5100, 4203.5900, 4226.6700, 4206.1500, 4277.4400,\n",
       "         4616.4100, 4351.7900],\n",
       "        [4296.4100, 4003.5900, 4262.5600, 4136.9200, 4340.5100, 4605.1300,\n",
       "         4096.4100, 4619.4900, 4197.4400, 4214.3600, 4193.3300, 4270.7700,\n",
       "         4607.1800, 4347.1800],\n",
       "        [4298.9700, 4006.1500, 4265.6400, 4131.7900, 4329.2300, 4604.6200,\n",
       "         4088.7200, 4612.8200, 4194.8700, 4211.7900, 4196.9200, 4276.4100,\n",
       "         4613.8500, 4358.9700],\n",
       "        [4314.8700, 4018.9700, 4283.0800, 4142.0500, 4337.9500, 4600.0000,\n",
       "         4084.1000, 4608.7200, 4201.5400, 4226.6700, 4215.3800, 4293.3300,\n",
       "         4629.7400, 4377.9500],\n",
       "        [4323.0800, 4019.4900, 4289.7400, 4151.7900, 4345.1300, 4596.9200,\n",
       "         4083.0800, 4613.8500, 4211.2800, 4244.6200, 4224.1000, 4300.5100,\n",
       "         4635.9000, 4378.9700],\n",
       "        [4309.7400, 4008.2100, 4281.0300, 4141.0300, 4334.3600, 4602.0500,\n",
       "         4084.6200, 4618.9700, 4212.8200, 4242.0500, 4213.3300, 4289.7400,\n",
       "         4625.6400, 4363.5900],\n",
       "        [4296.4100, 4000.5100, 4274.8700, 4131.7900, 4331.7900, 4603.0800,\n",
       "         4086.6700, 4622.0500, 4209.2300, 4228.7200, 4204.1000, 4280.0000,\n",
       "         4614.3600, 4356.4100],\n",
       "        [4305.6400, 4003.0800, 4278.9700, 4140.0000, 4346.1500, 4600.0000,\n",
       "         4086.1500, 4623.5900, 4207.1800, 4231.2800, 4207.1800, 4284.1000,\n",
       "         4617.9500, 4358.4600],\n",
       "        [4318.4600, 4005.1300, 4281.5400, 4143.0800, 4348.2100, 4605.6400,\n",
       "         4089.2300, 4624.1000, 4207.1800, 4231.2800, 4211.7900, 4288.7200,\n",
       "         4623.0800, 4362.0500],\n",
       "        [4313.3300, 4001.5400, 4277.9500, 4136.9200, 4338.4600, 4609.7400,\n",
       "         4091.7900, 4631.2800, 4214.3600, 4227.1800, 4211.7900, 4288.7200,\n",
       "         4624.6200, 4370.7700],\n",
       "        [4305.1300, 4004.1000, 4278.9700, 4137.4400, 4340.0000, 4602.5600,\n",
       "         4087.6900, 4635.9000, 4220.0000, 4235.3800, 4218.4600, 4291.7900,\n",
       "         4630.7700, 4377.9500],\n",
       "        [4306.6700, 4008.2100, 4276.9200, 4142.0500, 4343.0800, 4602.0500,\n",
       "         4084.1000, 4631.7900, 4218.9700, 4237.4400, 4225.1300, 4293.3300,\n",
       "         4631.7900, 4371.7900],\n",
       "        [4309.2300, 4004.6200, 4264.6200, 4136.9200, 4338.9700, 4608.7200,\n",
       "         4085.1300, 4629.2300, 4215.9000, 4230.2600, 4217.9500, 4286.6700,\n",
       "         4622.5600, 4361.0300],\n",
       "        [4308.2100, 4002.0500, 4260.0000, 4130.2600, 4345.1300, 4607.6900,\n",
       "         4082.0500, 4626.1500, 4208.2100, 4231.2800, 4210.7700, 4278.4600,\n",
       "         4617.4400, 4362.5600],\n",
       "        [4304.6200, 4001.5400, 4260.0000, 4127.6900, 4356.9200, 4604.6200,\n",
       "         4080.5100, 4616.9200, 4198.9700, 4232.3100, 4211.7900, 4275.3800,\n",
       "         4622.0500, 4362.0500],\n",
       "        [4301.0300, 4002.0500, 4250.2600, 4123.0800, 4350.7700, 4606.6700,\n",
       "         4085.1300, 4614.8700, 4196.4100, 4223.5900, 4210.2600, 4271.7900,\n",
       "         4621.5400, 4357.4400],\n",
       "        [4303.5900, 4005.6400, 4250.2600, 4124.6200, 4343.0800, 4607.1800,\n",
       "         4082.5600, 4620.5100, 4197.9500, 4223.5900, 4208.2100, 4272.8200,\n",
       "         4616.4100, 4359.4900],\n",
       "        [4305.6400, 4007.6900, 4261.5400, 4134.3600, 4352.8200, 4606.1500,\n",
       "         4078.4600, 4624.1000, 4200.5100, 4231.7900, 4212.8200, 4282.5600,\n",
       "         4615.9000, 4360.5100],\n",
       "        [4300.5100, 4003.0800, 4258.4600, 4131.2800, 4352.3100, 4606.1500,\n",
       "         4076.4100, 4624.1000, 4206.1500, 4233.3300, 4212.3100, 4283.5900,\n",
       "         4614.3600, 4352.3100],\n",
       "        [4295.3800, 3997.4400, 4245.1300, 4118.9700, 4335.3800, 4602.5600,\n",
       "         4075.3800, 4620.0000, 4204.1000, 4225.6400, 4203.5900, 4270.7700,\n",
       "         4609.2300, 4345.6400],\n",
       "        [4298.4600, 3998.4600, 4244.1000, 4120.0000, 4333.8500, 4600.0000,\n",
       "         4076.4100, 4612.3100, 4193.3300, 4220.0000, 4202.5600, 4265.1300,\n",
       "         4607.6900, 4352.3100],\n",
       "        [4304.6200, 4004.1000, 4253.3300, 4125.1300, 4345.6400, 4601.5400,\n",
       "         4080.5100, 4610.7700, 4192.3100, 4224.1000, 4208.7200, 4273.3300,\n",
       "         4611.2800, 4361.5400],\n",
       "        [4305.6400, 4002.0500, 4260.5100, 4120.5100, 4343.5900, 4603.5900,\n",
       "         4085.1300, 4618.4600, 4195.3800, 4219.4900, 4209.7400, 4279.4900,\n",
       "         4611.7900, 4360.5100],\n",
       "        [4301.5400, 3998.9700, 4262.5600, 4118.9700, 4337.4400, 4603.5900,\n",
       "         4082.0500, 4619.4900, 4195.3800, 4218.9700, 4211.2800, 4284.1000,\n",
       "         4614.8700, 4355.9000],\n",
       "        [4300.0000, 4005.1300, 4262.0500, 4122.5600, 4341.0300, 4599.4900,\n",
       "         4078.4600, 4614.3600, 4202.0500, 4235.3800, 4218.4600, 4289.2300,\n",
       "         4625.1300, 4362.0500],\n",
       "        [4304.6200, 4009.7400, 4263.5900, 4124.6200, 4349.2300, 4599.4900,\n",
       "         4084.6200, 4620.0000, 4209.7400, 4243.0800, 4223.0800, 4288.7200,\n",
       "         4628.2100, 4369.2300],\n",
       "        [4312.3100, 4005.1300, 4268.7200, 4123.5900, 4349.7400, 4606.6700,\n",
       "         4093.3300, 4629.2300, 4208.2100, 4236.4100, 4223.5900, 4290.7700,\n",
       "         4627.1800, 4368.7200],\n",
       "        [4315.3800, 4003.0800, 4272.3100, 4123.0800, 4345.1300, 4611.7900,\n",
       "         4092.8200, 4629.7400, 4213.8500, 4242.0500, 4225.1300, 4295.9000,\n",
       "         4632.8200, 4372.3100],\n",
       "        [4309.7400, 4005.1300, 4269.2300, 4121.5400, 4344.6200, 4607.1800,\n",
       "         4088.7200, 4628.7200, 4221.0300, 4245.1300, 4224.1000, 4291.7900,\n",
       "         4632.3100, 4375.3800],\n",
       "        [4300.0000, 4002.0500, 4261.0300, 4117.9500, 4345.6400, 4601.0300,\n",
       "         4087.1800, 4624.6200, 4209.2300, 4231.7900, 4215.9000, 4283.0800,\n",
       "         4623.0800, 4367.6900],\n",
       "        [4300.0000, 4001.5400, 4262.0500, 4121.0300, 4342.5600, 4600.5100,\n",
       "         4085.1300, 4618.9700, 4200.5100, 4228.7200, 4209.2300, 4284.1000,\n",
       "         4616.9200, 4357.9500],\n",
       "        [4305.6400, 4007.1800, 4265.6400, 4126.1500, 4341.5400, 4603.0800,\n",
       "         4088.2100, 4620.0000, 4202.0500, 4231.7900, 4211.2800, 4286.1500,\n",
       "         4615.9000, 4356.4100],\n",
       "        [4297.9500, 4004.1000, 4255.3800, 4117.9500, 4337.9500, 4602.0500,\n",
       "         4089.7400, 4620.5100, 4197.9500, 4220.5100, 4209.7400, 4278.9700,\n",
       "         4610.2600, 4354.3600],\n",
       "        [4287.1800, 3992.3100, 4245.1300, 4105.6400, 4328.7200, 4600.5100,\n",
       "         4087.1800, 4618.9700, 4201.0300, 4214.8700, 4203.5900, 4272.3100,\n",
       "         4605.1300, 4353.3300]], dtype=torch.float64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b717f71c673656192d67120db4b173d9f66f897f684497bd1a95a6c53d17ffdb"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('deep-learning-WCNYFuaf-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
