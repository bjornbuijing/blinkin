{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "We will explore this dataset: https://archive.ics.uci.edu/ml/datasets/EEG+Eye+State#\n",
    "\n",
    "> All data is from one continuous EEG measurement with the Emotiv EEG Neuroheadset. The duration of the measurement was 117 seconds. The eye state was detected via a camera during the EEG measurement and added later manually to the file after analysing the video frames. '1' indicates the eye-closed and '0' the eye-open state. All values are in chronological order with the first measured value at the top of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sys import path\n",
    "import torch\n",
    "import torch.utils.data.dataloader\n",
    "import numpy as np\n",
    "path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-07 14:16:16.537310: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-07 14:16:16.537338: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "data_dir = \"../../data/raw\"\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00264/EEG%20Eye%20State.arff\"\n",
    "datapath = tf.keras.utils.get_file(\n",
    "        \"eeg\", origin=url, untar=False, cache_dir=data_dir\n",
    "    )\n",
    "\n",
    "from scipy.io import arff\n",
    "data = arff.loadarff(datapath)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, scipy.io.arff._arffread.MetaData)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data[0]) , type (data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata = data[0].tolist()\n",
    "type(newdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Tuple\n",
    "Tensor = torch.Tensor\n",
    "\n",
    "class BaseListDataset():\n",
    "    \"\"\"Base class for loading list data\n",
    "    \"\"\"\n",
    "    def __init__(self, data: list):\n",
    "        self.data = data\n",
    "        self.dataset = []\n",
    "        self.process_data()\n",
    "    \n",
    "    def process_data(self) -> None:\n",
    "        # abstract function which needs to be inherited\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[Tensor, int]:\n",
    "        return self.dataset[idx]\n",
    "\n",
    "class EEGListDataset(BaseListDataset):\n",
    "    \"\"\"Processes data for EEG Lists\n",
    "\n",
    "    Args:\n",
    "        BaseListDataset (_type_): base class for list data\n",
    "    \"\"\"\n",
    "    def process_data(self) -> None:\n",
    "        for record in self.data:\n",
    "            x = torch.tensor([record[0],record[1],record[2],record[3],\n",
    "                             record[4],record[5],record[6],record[7],\n",
    "                             record[8],record[9],record[10],record[11],\n",
    "                             record[12],record[13]],dtype=float\n",
    "                            )\n",
    "            y= torch.tensor(int(record[14]))\n",
    "            self.dataset.append((x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsNew = EEGListDataset(data=data[0].tolist())\n",
    "x,y = dsNew[12000]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class BaseDataIterator:\n",
    "    def __init__(self, dataset: BaseListDataset, batchsize: int):\n",
    "        self.dataset = dataset\n",
    "        self.batchsize = batchsize\n",
    "        self.curindex = 0\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        # the lenght is the amount of batches\n",
    "        return int(len(self.dataset) / self.batchsize)\n",
    "\n",
    "    def __iter__(self) -> BaseDataIterator:\n",
    "        # initialize index\n",
    "        self.index = 0\n",
    "        self.index_list = torch.randperm(len(self.dataset))\n",
    "        return self\n",
    "    \n",
    "    def batchloop(self) -> Tuple[Tensor, Tensor]:\n",
    "        X = []  # noqa N806\n",
    "        Y = []  # noqa N806\n",
    "        # fill the batch\n",
    "        for _ in range(self.batchsize):\n",
    "            x, y = self.dataset[int(self.index_list[self.index])]\n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "            self.index += 1\n",
    "        return X, Y\n",
    "\n",
    "    def __next__(self) -> Tuple[Tensor, Tensor]:\n",
    "        if self.index <= (len(self.dataset) - self.batchsize):\n",
    "            X, Y = self.batchloop()\n",
    "            return X, Y\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "\n",
    "class PaddedDatagenerator(BaseDataIterator):\n",
    "    # again, we inherit everything from the baseclass\n",
    "    def __init__(self, dataset: BaseListDataset\t, batchsize: int) -> None:\n",
    "        # we initialize the super class BaseDataIterator\n",
    "        # we now have everything the BaseDataIterator can do, for free\n",
    "        super().__init__(dataset, batchsize)\n",
    "    \n",
    "    def __next__(self) -> Tuple[Tensor, Tensor]:\n",
    "        if self.index <= (len(self.dataset) - self.batchsize):\n",
    "            X, Y = self.batchloop()\n",
    "            # I do not have a clue why this function returns a tensort and torch.tensor(X) gives me an error\n",
    "            X_ = pad_sequence(X, batch_first=True, padding_value=0)  # noqa N806\n",
    "            return X_, torch.tensor(Y)\n",
    "        else:\n",
    "            raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = PaddedDatagenerator(dsNew, batchsize=32)\n",
    "testloader = PaddedDatagenerator(dsNew, batchsize=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 14]), torch.Size([32]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(trainloader))\n",
    "x.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SwitchIterator:\n",
    "    def __init__(self, dataset: BaseListDataset):\n",
    "        self.dataset = dataset\n",
    "        self.curindex = 0\n",
    "        self.index = 0\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        # the lenght is the amount of batches\n",
    "        return int(len(self.dataset) / self.batchsize)\n",
    "\n",
    "    def __iter__(self) -> BaseDataIterator:\n",
    "        # initialize index\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def batchloop(self) -> Tuple[Tensor, Tensor]:\n",
    "        X = []  # noqa N806\n",
    "        Y = []  # noqa N806\n",
    "        # fill the batch\n",
    "        x, y = self.dataset[int(self.index)]\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "        self.index = self.index + 1 \n",
    "        currentY = y\n",
    "        while y == currentY:\n",
    "            if self.index +1 < len(self.dataset):\n",
    "                X.append(x)\n",
    "                Y.append(y)  \n",
    "                self.index = self.index + 1      \n",
    "                x, y = self.dataset[int(self.index)]                   \n",
    "            else:\n",
    "                self.index = 0\n",
    "                break                               \n",
    "     \n",
    "        return X, Y\n",
    "\n",
    "    def __next__(self) -> Tuple[Tensor, Tensor]:\n",
    "        if self.index < (len(self.dataset)):            \n",
    "            X, Y = self.batchloop()\n",
    "            return X, Y\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "\n",
    "class SwitchPaddedDatagenerator(SwitchIterator):\n",
    "    # again, we inherit everything from the baseclass\n",
    "    def __init__(self, dataset: BaseListDataset) -> None:\n",
    "        # we initialize the super class BaseDataIterator\n",
    "        # we now have everything the BaseDataIterator can do, for free\n",
    "        super().__init__(dataset)\n",
    "    \n",
    "    def __next__(self) -> Tuple[Tensor, Tensor]:\n",
    "        if self.index < (len(self.dataset)):\n",
    "            X, Y = self.batchloop()\n",
    "            # we just want to add padding\n",
    "            X_ = pad_sequence(X, batch_first=True, padding_value=0)  # noqa N806\n",
    "            return X_, torch.tensor(Y)\n",
    "        else:\n",
    "            raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = SwitchPaddedDatagenerator(dsNew)\n",
    "testloader = SwitchPaddedDatagenerator(dsNew)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,23):\n",
    "    x, y = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([670, 14])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(trainloader))\n",
    "x.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4424.1000, 4087.6900, 4311.2800,  ..., 4314.8700, 4675.9000,\n",
       "         4466.6700],\n",
       "        [4424.1000, 4087.6900, 4311.2800,  ..., 4314.8700, 4675.9000,\n",
       "         4466.6700],\n",
       "        [4417.9500, 4081.5400, 4310.7700,  ..., 4318.4600, 4693.8500,\n",
       "         4462.5600],\n",
       "        ...,\n",
       "        [4322.0500, 4034.8700, 4280.0000,  ..., 4291.7900, 4617.4400,\n",
       "         4375.9000],\n",
       "        [4315.9000, 4031.7900, 4275.3800,  ..., 4285.6400, 4618.4600,\n",
       "         4376.9200],\n",
       "        [4315.9000, 4027.6900, 4275.9000,  ..., 4282.0500, 4618.4600,\n",
       "         4374.3600]], dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGBatchIterator:\n",
    "    def __init__(self, dataset: BaseListDataset, batchsize: int):\n",
    "        self.dataset = dataset\n",
    "        self.batchsize = batchsize\n",
    "        self.curindex = 0\n",
    "        self.index = 0\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        # the lenght is the amount of batches\n",
    "        return int(len(self.dataset) / self.batchsize)\n",
    "\n",
    "    def __iter__(self) -> BaseDataIterator:\n",
    "        # initialize index\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def batchloop(self) -> Tuple[Tensor, Tensor]:\n",
    "        X = []  # noqa N806\n",
    "        Y = []  # noqa N806\n",
    "        # fill the batch\n",
    "        x, y = self.dataset[int(self.index)]\n",
    "        count = 1\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "        self.index = self.index + 1 \n",
    "        currentY = y\n",
    "        while y == currentY and count < self.batchsize :\n",
    "            if self.index == self.__len__:\n",
    "                break\n",
    "            else:                                 \n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "                count = count +1\n",
    "                self.index = self.index + 1      \n",
    "                x, y = self.dataset[int(self.index)]        \n",
    "        return X, Y\n",
    "\n",
    "    def __next__(self) -> Tuple[Tensor, Tensor]:\n",
    "        if self.index <= (len(self.dataset)):\n",
    "            X, Y = self.batchloop()\n",
    "            # we just want to add padding\n",
    "            X_ = pad_sequence(X, batch_first=True, padding_value=0)  # noqa N806\n",
    "            return X_, torch.tensor(Y)\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader2 = EEGBatchIterator(dsNew, batchsize=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 14]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(trainloader2))\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4329.2300, 4009.2300, 4289.2300, 4148.2100, 4350.2600, 4586.1500,\n",
       "         4096.9200, 4641.0300, 4222.0500, 4238.4600, 4211.2800, 4280.5100,\n",
       "         4635.9000, 4393.8500],\n",
       "        [4329.2300, 4009.2300, 4289.2300, 4148.2100, 4350.2600, 4586.1500,\n",
       "         4096.9200, 4641.0300, 4222.0500, 4238.4600, 4211.2800, 4280.5100,\n",
       "         4635.9000, 4393.8500],\n",
       "        [4327.6900, 4006.6700, 4295.3800, 4156.4100, 4336.9200, 4583.5900,\n",
       "         4096.9200, 4630.2600, 4207.6900, 4222.0500, 4206.6700, 4282.0500,\n",
       "         4628.7200, 4389.2300],\n",
       "        [4328.7200, 4011.7900, 4296.4100, 4155.9000, 4343.5900, 4582.5600,\n",
       "         4097.4400, 4630.7700, 4217.4400, 4235.3800, 4210.7700, 4287.6900,\n",
       "         4632.3100, 4396.4100],\n",
       "        [4326.1500, 4011.7900, 4292.3100, 4151.2800, 4347.6900, 4586.6700,\n",
       "         4095.9000, 4627.6900, 4210.7700, 4244.1000, 4212.8200, 4288.2100,\n",
       "         4632.8200, 4398.4600],\n",
       "        [4321.0300, 4004.6200, 4284.1000, 4153.3300, 4345.6400, 4587.1800,\n",
       "         4093.3300, 4616.9200, 4202.5600, 4232.8200, 4209.7400, 4281.0300,\n",
       "         4628.2100, 4389.7400],\n",
       "        [4319.4900, 4001.0300, 4280.5100, 4151.7900, 4343.5900, 4584.6200,\n",
       "         4089.7400, 4615.9000, 4212.3100, 4226.6700, 4201.0300, 4269.7400,\n",
       "         4625.1300, 4378.4600],\n",
       "        [4325.6400, 4006.6700, 4278.4600, 4143.0800, 4344.1000, 4583.0800,\n",
       "         4087.1800, 4614.8700, 4205.6400, 4230.2600, 4195.9000, 4266.6700,\n",
       "         4622.0500, 4380.5100],\n",
       "        [4326.1500, 4010.7700, 4276.4100, 4139.4900, 4345.1300, 4584.1000,\n",
       "         4091.2800, 4608.2100, 4187.6900, 4229.7400, 4202.0500, 4273.8500,\n",
       "         4627.1800, 4389.7400],\n",
       "        [4326.1500, 4011.2800, 4276.9200, 4142.0500, 4344.1000, 4582.5600,\n",
       "         4092.8200, 4608.7200, 4194.3600, 4228.7200, 4212.8200, 4277.9500,\n",
       "         4637.4400, 4393.3300],\n",
       "        [4326.1500, 4010.7700, 4272.8200, 4143.0800, 4342.5600, 4579.4900,\n",
       "         4087.6900, 4615.9000, 4206.1500, 4228.7200, 4210.7700, 4272.8200,\n",
       "         4631.7900, 4382.5600],\n",
       "        [4316.9200, 4002.5600, 4259.4900, 4135.9000, 4339.4900, 4581.5400,\n",
       "         4086.1500, 4615.3800, 4195.9000, 4223.5900, 4197.4400, 4262.0500,\n",
       "         4613.3300, 4370.7700],\n",
       "        [4308.2100, 3993.3300, 4247.6900, 4124.6200, 4335.9000, 4584.6200,\n",
       "         4089.7400, 4610.2600, 4188.7200, 4221.5400, 4190.2600, 4255.9000,\n",
       "         4606.1500, 4369.7400],\n",
       "        [4308.2100, 3998.4600, 4251.7900, 4122.5600, 4338.4600, 4584.6200,\n",
       "         4091.2800, 4616.9200, 4205.6400, 4225.6400, 4194.3600, 4263.5900,\n",
       "         4610.2600, 4371.2800],\n",
       "        [4312.8200, 4006.1500, 4260.5100, 4127.6900, 4341.0300, 4586.1500,\n",
       "         4089.7400, 4628.7200, 4215.9000, 4225.1300, 4198.9700, 4274.3600,\n",
       "         4611.7900, 4375.9000],\n",
       "        [4313.8500, 4003.5900, 4255.9000, 4127.6900, 4337.9500, 4586.1500,\n",
       "         4091.2800, 4627.6900, 4206.1500, 4224.6200, 4199.4900, 4269.2300,\n",
       "         4610.2600, 4378.9700],\n",
       "        [4306.6700, 3997.9500, 4247.1800, 4122.5600, 4336.9200, 4584.1000,\n",
       "         4094.3600, 4620.5100, 4202.5600, 4226.1500, 4193.8500, 4254.3600,\n",
       "         4606.1500, 4369.7400],\n",
       "        [4303.5900, 3996.4100, 4249.2300, 4122.0500, 4341.0300, 4584.1000,\n",
       "         4090.7700, 4616.4100, 4203.5900, 4226.1500, 4189.2300, 4253.8500,\n",
       "         4606.1500, 4370.2600],\n",
       "        [4312.3100, 4000.0000, 4255.9000, 4124.1000, 4342.0500, 4586.6700,\n",
       "         4085.6400, 4610.7700, 4192.3100, 4223.0800, 4192.3100, 4264.6200,\n",
       "         4614.8700, 4382.0500],\n",
       "        [4315.9000, 4003.5900, 4257.4400, 4122.5600, 4341.5400, 4588.2100,\n",
       "         4088.2100, 4607.1800, 4188.2100, 4216.9200, 4200.0000, 4270.2600,\n",
       "         4621.5400, 4378.9700],\n",
       "        [4314.3600, 4005.6400, 4259.4900, 4123.5900, 4345.1300, 4588.2100,\n",
       "         4092.3100, 4612.8200, 4206.6700, 4222.5600, 4209.7400, 4272.3100,\n",
       "         4624.6200, 4381.5400],\n",
       "        [4324.6200, 4012.8200, 4263.0800, 4132.3100, 4343.0800, 4587.1800,\n",
       "         4091.7900, 4617.9500, 4213.3300, 4240.5100, 4217.9500, 4274.3600,\n",
       "         4632.3100, 4400.5100],\n",
       "        [4331.2800, 4024.1000, 4266.1500, 4140.0000, 4336.4100, 4585.6400,\n",
       "         4089.7400, 4617.9500, 4204.6200, 4245.1300, 4216.4100, 4274.3600,\n",
       "         4638.9700, 4401.5400],\n",
       "        [4326.6700, 4020.0000, 4264.1000, 4137.4400, 4334.3600, 4586.1500,\n",
       "         4088.2100, 4621.5400, 4213.3300, 4238.4600, 4208.7200, 4271.2800,\n",
       "         4634.3600, 4385.1300],\n",
       "        [4321.5400, 4007.6900, 4260.0000, 4132.3100, 4340.0000, 4585.6400,\n",
       "         4087.1800, 4630.2600, 4230.2600, 4242.5600, 4208.7200, 4270.2600,\n",
       "         4627.6900, 4378.9700],\n",
       "        [4317.4400, 4007.6900, 4257.4400, 4128.7200, 4343.5900, 4585.1300,\n",
       "         4088.2100, 4638.9700, 4231.7900, 4247.6900, 4209.2300, 4269.7400,\n",
       "         4625.1300, 4386.1500],\n",
       "        [4311.7900, 4007.1800, 4250.7700, 4125.1300, 4336.4100, 4587.1800,\n",
       "         4087.6900, 4634.3600, 4209.2300, 4232.3100, 4197.4400, 4262.0500,\n",
       "         4615.3800, 4381.0300],\n",
       "        [4308.7200, 4000.0000, 4245.1300, 4121.5400, 4329.2300, 4585.6400,\n",
       "         4086.6700, 4617.4400, 4189.2300, 4216.4100, 4186.1500, 4253.8500,\n",
       "         4604.1000, 4362.0500],\n",
       "        [4308.2100, 4002.0500, 4252.8200, 4122.5600, 4332.8200, 4582.5600,\n",
       "         4087.6900, 4610.7700, 4192.8200, 4216.4100, 4189.7400, 4256.9200,\n",
       "         4605.1300, 4360.0000],\n",
       "        [4311.2800, 4011.2800, 4265.1300, 4130.2600, 4339.4900, 4583.5900,\n",
       "         4089.7400, 4616.4100, 4200.0000, 4220.5100, 4195.9000, 4265.6400,\n",
       "         4611.2800, 4374.3600],\n",
       "        [4311.2800, 4008.7200, 4265.1300, 4130.7700, 4337.4400, 4585.6400,\n",
       "         4087.6900, 4614.8700, 4190.2600, 4218.4600, 4195.3800, 4265.6400,\n",
       "         4608.7200, 4374.3600],\n",
       "        [4306.1500, 4000.5100, 4259.4900, 4121.0300, 4330.2600, 4584.1000,\n",
       "         4085.6400, 4607.1800, 4185.1300, 4216.9200, 4200.0000, 4263.0800,\n",
       "         4611.2800, 4369.2300],\n",
       "        [4307.1800, 4003.0800, 4263.0800, 4121.5400, 4330.7700, 4582.5600,\n",
       "         4086.6700, 4611.7900, 4202.0500, 4224.6200, 4208.7200, 4271.2800,\n",
       "         4622.5600, 4379.4900],\n",
       "        [4314.8700, 4008.2100, 4268.2100, 4128.2100, 4335.3800, 4584.1000,\n",
       "         4092.3100, 4625.6400, 4212.8200, 4231.2800, 4210.7700, 4275.9000,\n",
       "         4624.6200, 4382.5600],\n",
       "        [4313.8500, 4003.0800, 4263.5900, 4124.1000, 4336.4100, 4586.6700,\n",
       "         4100.5100, 4633.3300, 4215.3800, 4232.8200, 4207.1800, 4270.7700,\n",
       "         4618.9700, 4372.3100],\n",
       "        [4308.2100, 3997.4400, 4254.3600, 4119.4900, 4332.8200, 4588.7200,\n",
       "         4097.9500, 4628.2100, 4217.4400, 4235.3800, 4208.2100, 4268.7200,\n",
       "         4621.5400, 4368.2100],\n",
       "        [4308.7200, 4006.1500, 4253.3300, 4121.0300, 4330.2600, 4585.6400,\n",
       "         4082.0500, 4614.8700, 4202.5600, 4236.4100, 4208.7200, 4271.2800,\n",
       "         4628.2100, 4370.2600],\n",
       "        [4306.1500, 4007.6900, 4253.3300, 4121.0300, 4330.2600, 4579.4900,\n",
       "         4077.4400, 4607.6900, 4186.6700, 4224.6200, 4198.9700, 4267.1800,\n",
       "         4622.5600, 4367.1800],\n",
       "        [4297.4400, 3992.8200, 4249.7400, 4118.4600, 4330.7700, 4581.0300,\n",
       "         4085.6400, 4609.2300, 4189.2300, 4208.7200, 4187.1800, 4258.9700,\n",
       "         4606.1500, 4363.5900],\n",
       "        [4301.0300, 3994.3600, 4252.8200, 4119.4900, 4332.8200, 4583.0800,\n",
       "         4087.6900, 4611.7900, 4195.9000, 4210.2600, 4188.2100, 4260.5100,\n",
       "         4601.0300, 4366.6700],\n",
       "        [4313.8500, 4010.7700, 4260.0000, 4124.6200, 4337.4400, 4580.5100,\n",
       "         4088.7200, 4618.4600, 4203.5900, 4223.5900, 4198.9700, 4267.6900,\n",
       "         4613.3300, 4370.7700],\n",
       "        [4317.4400, 4010.7700, 4258.4600, 4126.1500, 4339.4900, 4584.1000,\n",
       "         4094.3600, 4625.6400, 4208.2100, 4229.7400, 4201.5400, 4271.2800,\n",
       "         4619.4900, 4376.4100],\n",
       "        [4305.6400, 3998.4600, 4251.7900, 4121.5400, 4331.7900, 4584.6200,\n",
       "         4094.8700, 4620.0000, 4200.0000, 4222.0500, 4196.9200, 4268.7200,\n",
       "         4610.7700, 4370.2600],\n",
       "        [4296.9200, 3995.3800, 4249.2300, 4120.5100, 4324.6200, 4577.9500,\n",
       "         4088.2100, 4615.9000, 4203.0800, 4213.3300, 4197.9500, 4262.5600,\n",
       "         4606.1500, 4357.4400],\n",
       "        [4298.9700, 4001.0300, 4247.6900, 4123.0800, 4332.8200, 4580.0000,\n",
       "         4087.1800, 4624.6200, 4220.5100, 4224.1000, 4205.6400, 4265.1300,\n",
       "         4615.3800, 4363.0800],\n",
       "        [4302.5600, 4006.6700, 4249.7400, 4120.5100, 4342.0500, 4589.2300,\n",
       "         4094.8700, 4627.6900, 4216.4100, 4241.5400, 4217.9500, 4274.8700,\n",
       "         4627.6900, 4375.9000],\n",
       "        [4308.7200, 4006.1500, 4256.4100, 4118.4600, 4333.8500, 4587.6900,\n",
       "         4097.9500, 4621.5400, 4206.6700, 4243.5900, 4223.0800, 4276.4100,\n",
       "         4633.3300, 4376.9200],\n",
       "        [4315.3800, 4000.5100, 4262.5600, 4120.5100, 4329.2300, 4583.5900,\n",
       "         4092.8200, 4621.5400, 4210.2600, 4240.0000, 4218.9700, 4277.4400,\n",
       "         4633.8500, 4381.0300],\n",
       "        [4317.9500, 4004.6200, 4268.7200, 4123.5900, 4337.9500, 4585.1300,\n",
       "         4087.1800, 4622.0500, 4207.1800, 4242.0500, 4217.4400, 4285.6400,\n",
       "         4634.8700, 4388.2100],\n",
       "        [4316.4100, 4013.8500, 4267.6900, 4124.6200, 4342.5600, 4589.7400,\n",
       "         4089.2300, 4616.4100, 4200.5100, 4232.8200, 4213.3300, 4281.0300,\n",
       "         4630.2600, 4375.9000],\n",
       "        [4305.1300, 4008.7200, 4259.4900, 4120.0000, 4341.0300, 4595.9000,\n",
       "         4092.8200, 4612.3100, 4199.4900, 4219.4900, 4198.4600, 4261.0300,\n",
       "         4611.7900, 4357.9500],\n",
       "        [4293.3300, 3994.8700, 4254.3600, 4116.4100, 4337.4400, 4596.4100,\n",
       "         4092.3100, 4609.7400, 4193.3300, 4211.7900, 4186.6700, 4252.8200,\n",
       "         4597.9500, 4347.6900],\n",
       "        [4297.4400, 3994.3600, 4258.4600, 4118.9700, 4336.9200, 4594.3600,\n",
       "         4096.9200, 4614.3600, 4193.3300, 4209.7400, 4192.3100, 4260.5100,\n",
       "         4602.0500, 4350.7700],\n",
       "        [4308.2100, 4007.1800, 4268.2100, 4126.1500, 4344.6200, 4595.3800,\n",
       "         4102.0500, 4622.5600, 4205.1300, 4221.5400, 4205.1300, 4271.7900,\n",
       "         4614.3600, 4374.8700],\n",
       "        [4315.9000, 4021.0300, 4277.9500, 4134.3600, 4346.1500, 4591.2800,\n",
       "         4095.9000, 4620.0000, 4208.7200, 4235.3800, 4212.3100, 4280.5100,\n",
       "         4625.6400, 4391.7900],\n",
       "        [4329.2300, 4026.1500, 4281.0300, 4141.0300, 4336.9200, 4585.6400,\n",
       "         4085.6400, 4613.3300, 4203.5900, 4233.8500, 4213.3300, 4281.5400,\n",
       "         4630.7700, 4387.1800],\n",
       "        [4335.9000, 4024.6200, 4281.0300, 4144.1000, 4336.4100, 4591.2800,\n",
       "         4088.7200, 4616.4100, 4202.0500, 4233.3300, 4211.7900, 4274.8700,\n",
       "         4631.2800, 4385.6400],\n",
       "        [4324.6200, 4018.9700, 4276.4100, 4135.9000, 4341.5400, 4600.5100,\n",
       "         4099.4900, 4626.1500, 4211.2800, 4242.0500, 4216.4100, 4276.9200,\n",
       "         4632.8200, 4388.7200],\n",
       "        [4314.8700, 4011.2800, 4268.7200, 4122.5600, 4334.3600, 4602.0500,\n",
       "         4100.5100, 4632.3100, 4222.5600, 4243.0800, 4221.0300, 4283.5900,\n",
       "         4630.2600, 4381.0300],\n",
       "        [4312.8200, 4005.6400, 4266.1500, 4124.6200, 4333.3300, 4601.0300,\n",
       "         4100.5100, 4632.3100, 4218.4600, 4240.0000, 4216.4100, 4278.4600,\n",
       "         4622.0500, 4374.8700],\n",
       "        [4312.3100, 4009.2300, 4270.2600, 4134.3600, 4344.1000, 4600.5100,\n",
       "         4099.4900, 4629.2300, 4209.2300, 4240.5100, 4213.3300, 4276.4100,\n",
       "         4621.5400, 4380.0000],\n",
       "        [4312.8200, 4010.2600, 4268.7200, 4129.7400, 4344.6200, 4602.0500,\n",
       "         4095.9000, 4629.7400, 4214.3600, 4236.4100, 4214.8700, 4282.0500,\n",
       "         4624.1000, 4375.9000],\n",
       "        [4308.2100, 4003.5900, 4264.6200, 4121.5400, 4333.8500, 4601.0300,\n",
       "         4094.8700, 4631.7900, 4215.3800, 4228.7200, 4208.2100, 4278.9700,\n",
       "         4612.8200, 4363.0800],\n",
       "        [4299.4900, 4002.5600, 4265.6400, 4123.0800, 4332.3100, 4592.3100,\n",
       "         4088.2100, 4619.4900, 4193.3300, 4221.0300, 4197.9500, 4268.7200,\n",
       "         4602.5600, 4358.4600]], dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16b8f312320cd240106b9ea4d318428341e8727b3c7d5fc1f73cfe4a3d9868ce"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('deep-learning-E14Cnx23-py3.9': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
